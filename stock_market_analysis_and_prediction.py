# -*- coding: utf-8 -*-
"""Stock Market Analysis and Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C3eqx6K01SKPCb97vv-i471GsOY6hJze

# Import data from yahoo finance
"""

# Commented out IPython magic to ensure Python compatibility.
# ✅ Step 1: Install yfinance
!pip install yfinance --quiet

# ✅ Step 2: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from datetime import datetime
import time

# Plot settings
sns.set_style('whitegrid')
plt.style.use("fivethirtyeight")
# %matplotlib inline

# ✅ Step 3: Define tickers and names
tech_list = ['NFLX', 'META', 'TSLA', 'NVDA']
company_name = ['NETFLIX', 'META', 'TESLA', 'NVIDIA']

# Date range: last 1 year
end = datetime.now()
start = datetime(end.year - 1, end.month, end.day)

# ✅ Step 4: Download and create individual variables
company_list = []

for ticker, name in zip(tech_list, company_name):
    print(f"Downloading data for {name} ({ticker})...")
    data = yf.download(ticker, start=start, end=end)
    if not data.empty:
        data["company_name"] = name
        globals()[ticker] = data  # Now you can use NFLX, META, etc.
        company_list.append(data)
    else:
        print(f"⚠️ No data for {ticker}")
    time.sleep(1)

# ✅ Step 5: Combine all into one DataFrame
if company_list:
    df = pd.concat(company_list)
    print("✅ Data download complete. Showing last 10 rows:")
    display(df.tail(10))
else:
    print("❌ No stock data was downloaded.")

"""# Description of Stocks"""

NFLX.describe()

META.describe()

TSLA.describe()

NVDA.describe()

"""# Closing price Graph"""



for name in company_name:
    df[df['company_name'] == name]['Close'].plot(figsize=(12, 4), title=f"{name} Closing Price")
    plt.xlabel("Date")
    plt.ylabel("Close Price (USD)")
    plt.show()
    print(" ")

"""# Plot sales volume"""

plt.figure(figsize=(16, 10))
plt.suptitle("Daily Trading Volume of Stocks (Last 1 Year)", fontsize=16, y=1.02)

for i, company in enumerate(company_list, 1):
    ax = plt.subplot(2, 2, i)
    company['Volume'].plot(ax=ax, color='dodgerblue')

    ax.set_ylabel('Volume')
    ax.set_xlabel('Date')
    ax.set_title(f"Sales Volume for {company['company_name'].iloc[0]}")

    ax.legend().remove()  # Remove legend if unnecessary
    ax.grid(True)

    # Fix extra axes artifacts
    for spine in ax.spines.values():
        spine.set_visible(False)  # Removes plot box borders

plt.tight_layout(pad=3.0)
plt.show()

"""# Moving Average"""

# ✅ Calculate moving averages for each company (10, 20, 50 days)
ma_days = [10, 20, 50]

for ma in ma_days:
    for company in company_list:
        column_name = f"MA for {ma} days"
        company[column_name] = company['Close'].rolling(window=ma).mean()

# ✅ Plot 4 subplots (one per stock)
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))

# Get variables from globals() for plotting
META[['Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,0])
axes[0,0].set_title('META')

NFLX[['Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,1])
axes[0,1].set_title('NETFLIX')

TSLA[['Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,0])
axes[1,0].set_title('TESLA')

NVDA[['Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,1])
axes[1,1].set_title('NVIDIA')

plt.tight_layout(pad=3.0)
plt.show()

"""# Percentage Change *Graph*"""



# ✅ Step 1: Calculate daily return using 'Close' price
for company in company_list:
    company['Daily Return'] = company['Close'].pct_change()

# ✅ Step 2: Plot daily returns for each company in a 2x2 subplot
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))

META['Daily Return'].plot(ax=axes[0, 0], legend=True, linestyle='--', marker='o')
axes[0, 0].set_title('META')

NFLX['Daily Return'].plot(ax=axes[0, 1], legend=True, linestyle='--', marker='o')
axes[0, 1].set_title('NETFLIX')

TSLA['Daily Return'].plot(ax=axes[1, 0], legend=True, linestyle='--', marker='o')
axes[1, 0].set_title('TESLA')

NVDA['Daily Return'].plot(ax=axes[1, 1], legend=True, linestyle='--', marker='o')
axes[1, 1].set_title('NVIDIA')

plt.tight_layout(pad=3.0)
plt.show()



"""# Daily Return Graph"""

plt.figure(figsize=(12, 9))

for i, company in enumerate(company_list, 1):
    plt.subplot(2, 2, i)
    company['Daily Return'].hist(bins=50)
    plt.xlabel('Daily Return')
    plt.ylabel('Counts')
    plt.title(f'{company_name[i - 1]}')

plt.tight_layout()

"""# Corerelation between different stocks closing prices"""

# ✅ Download stock data and get 'Close' prices
closing_df = yf.download(tech_list, start=start, end=end)['Close']

# ✅ Calculate daily returns (percentage change)
tech_rets = closing_df.pct_change()

# ✅ Display first few rows
print("Daily Return (% Change) based on Close Prices:")
tech_rets.head()

import seaborn as sns
import matplotlib.pyplot as plt

# Compare META to itself using daily return data
sns.jointplot(x='META', y='META', data=tech_rets, kind='scatter', color='seagreen')

plt.suptitle("META vs META Daily Return Scatter Plot", y=1.02)
plt.show()

"""# Comparision between tesla and netflix"""

# We'll use joinplot to compare the daily returns of TESLA and NETFLIX
sns.jointplot(x='TSLA', y='NFLX', data=tech_rets, kind='scatter')

# Set up our figure by naming it returns_fig, call PairPLot on the DataFrame
returns_fig = sns.PairGrid(closing_df)

# Using map_upper we can specify what the upper triangle will look like.
returns_fig.map_upper(plt.scatter,color='purple')

# We can also define the lower triangle in the figure, inclufing the plot type (kde) or the color map (BluePurple)
returns_fig.map_lower(sns.kdeplot,cmap='cool_d')

# Finally we'll define the diagonal as a series of histogram plots of the daily return
returns_fig.map_diag(plt.hist,bins=30)

"""# Correlation Analysis of Multiple Stock Closing Prices"""

plt.figure(figsize=(12, 10))

plt.subplot(2, 2, 1)
sns.heatmap(tech_rets.corr(), annot=True, cmap='summer')
plt.title('Correlation of stock return')

plt.subplot(2, 2, 2)
sns.heatmap(closing_df.corr(), annot=True, cmap='summer')
plt.title('Correlation of stock closing price')

"""# How much value do we put at risk by investing in a particular stock?"""

rets = tech_rets.dropna()

area = np.pi * 20

plt.figure(figsize=(10, 8))
plt.scatter(rets.mean(), rets.std(), s=area)
plt.xlabel('Expected return')
plt.ylabel('Risk')

for label, x, y in zip(rets.columns, rets.mean(), rets.std()):
    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom',
                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))

"""# Predicting closing price"""

# ✅ Download NVDA stock data from 2012 to today
df = yf.download('NVDA', start='2012-01-01', end=datetime.now())

# ✅ Show the data
df.tail()

plt.figure(figsize=(16,6))
plt.title('Close Price History')
plt.plot(df['Close'])
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.show()

# Create a new dataframe with only the 'Close column
data = df.filter(['Close'])
# Convert the dataframe to a numpy array
dataset = data.values
# Get the number of rows to train the model on
training_data_len = int(np.ceil( len(dataset) * .95 ))

training_data_len

# Step 1: Select 'Close' prices as a 2D DataFrame
dataset = df[['Close']]  # Double brackets keep shape as (n, 1)

# Step 2: Scale it between 0 and 1
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(dataset)

# Step 3: Show result
scaled_data[:5]

# Create the training data set
# Create the scaled training data set
train_data = scaled_data[0:int(training_data_len), :]
# Split the data into x_train and y_train data sets
x_train = []
y_train = []

for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i, 0])
    y_train.append(train_data[i, 0])
    if i<= 61:
        print(x_train)
        print(y_train)
        print()

# Convert the x_train and y_train to numpy arrays
x_train, y_train = np.array(x_train), np.array(y_train)

# Reshape the data
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
# x_train.shape

from keras.models import Sequential
from keras.layers import Dense, LSTM

# Build the LSTM model
model = Sequential()
model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))
model.add(LSTM(64, return_sequences=False))
model.add(Dense(50))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(x_train, y_train, batch_size=1, epochs=1)

"""# error calculation"""

# Convert dataset to numpy array before slicing
y_test = dataset[training_data_len:].values  # ✅ Fix here

# Create test features (x_test)
x_test = []
for i in range(60, len(test_data)):
    x_test.append(test_data[i-60:i, 0])

# Convert to numpy and reshape for LSTM
x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

# Predict using trained model
predictions = model.predict(x_test)

# Inverse scale the predictions to original values
predictions = scaler.inverse_transform(predictions)

# Calculate RMSE
rmse = np.sqrt(np.mean((predictions - y_test) ** 2))
rmse

print(train.columns)
print(valid.columns)

# Step 1: Make sure df is the original DataFrame with a 'Close' column
dataset = df[['Close']]  # Make sure 'df' is correct and has 'Close'

# Step 2: Re-split using dataset (not raw NumPy)
train = dataset[:training_data_len]
valid = dataset[training_data_len:].copy()

# Step 3: Assign predictions
valid['Predictions'] = predictions

# Step 4: Plot
plt.figure(figsize=(16,6))
plt.title('Model Prediction vs Actual Price')
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.plot(train['Close'], label='Train')
plt.plot(valid[['Close', 'Predictions']])
plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
plt.show()

"""# Predictions"""

valid

